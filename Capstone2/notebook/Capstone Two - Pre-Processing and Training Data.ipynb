{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Load The  Forest Cover Type Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "      <th>interact_Hillshade_9am3pm</th>\n",
       "      <th>interact_Hillshade_9amNoon</th>\n",
       "      <th>interact_Hillshade_3pmNoon</th>\n",
       "      <th>Euclidean_Distance_To_Hydrology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>32708</td>\n",
       "      <td>51272</td>\n",
       "      <td>34336</td>\n",
       "      <td>258.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33220</td>\n",
       "      <td>51700</td>\n",
       "      <td>35485</td>\n",
       "      <td>212.084889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31590</td>\n",
       "      <td>55692</td>\n",
       "      <td>32130</td>\n",
       "      <td>275.769832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29036</td>\n",
       "      <td>56644</td>\n",
       "      <td>29036</td>\n",
       "      <td>269.235956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33000</td>\n",
       "      <td>51480</td>\n",
       "      <td>35100</td>\n",
       "      <td>153.003268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type36  Soil_Type37  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \\\n",
       "0            0            0            0           5   \n",
       "1            0            0            0           5   \n",
       "2            0            0            0           2   \n",
       "3            0            0            0           2   \n",
       "4            0            0            0           5   \n",
       "\n",
       "   interact_Hillshade_9am3pm  interact_Hillshade_9amNoon  \\\n",
       "0                      32708                       51272   \n",
       "1                      33220                       51700   \n",
       "2                      31590                       55692   \n",
       "3                      29036                       56644   \n",
       "4                      33000                       51480   \n",
       "\n",
       "   interact_Hillshade_3pmNoon  Euclidean_Distance_To_Hydrology  \n",
       "0                       34336                       258.000000  \n",
       "1                       35485                       212.084889  \n",
       "2                       32130                       275.769832  \n",
       "3                       29036                       269.235956  \n",
       "4                       35100                       153.003268  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covtype = pd.read_csv('../data/covtype_step2_features.csv')\n",
    "covtype.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = covtype.loc[:, covtype.columns != 'Cover_Type']\n",
    "y = covtype.loc[:, covtype.columns == 'Cover_Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into trainning set, validation set, and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state = 42, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state  = 42, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371847, 58)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Target Encoding On Categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set has categorical features that are one-hot encoded,where soil type consists of 40 types and wilderness area consists of 4 types. The higher dimension of the feature matrix sometimes may cause the algorithm having a hard time to learn form the data, so we also want to explore if target encoding the categorical features will results in a better outcome.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_label(X, cat_name):   \n",
    "    '''transform the one hot encoding columns to a label column'''\n",
    "    \n",
    "    X = X.iloc[:, X.columns.str.contains(pat = cat_name + '.*')] \n",
    "    Label = X.apply(lambda row : row.argmax(), axis = 1)\n",
    "    return Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding(X, target, cat_name):\n",
    "    '''return the posterior probility of a cover type given a sample belonging to a certain category'''\n",
    "    \n",
    "    label = onehot_to_label(X, cat_name)\n",
    "    label_target = pd.DataFrame({cat_name: label, 'target': target.Cover_Type})\n",
    "    posterior_prob = pd.DataFrame(index = range(label.nunique()))\n",
    "    \n",
    "    #total 7 cover types\n",
    "    n = 7\n",
    "    for i in range(1, n+1):\n",
    "        label_target['ith_Covtype'] = np.array(target == i).astype('int')\n",
    "        encoded_feature = 'PProb_CovType' + str(i) + '|' + cat_name\n",
    "        posterior_prob[encoded_feature] = label_target[['ith_Covtype', cat_name]\n",
    "                                                      ].groupby(cat_name).mean() \n",
    "\n",
    "        label_target.drop(columns  = 'ith_Covtype', inplace = True)  \n",
    "        \n",
    "    return posterior_prob\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_encoded_features(X, encoded_features, cat_name):\n",
    "    '''replace the one-hot encoded features by target encoded features'''\n",
    "    X_copy = X.copy()\n",
    "    X_copy[cat_name] = onehot_to_label(X_copy, cat_name)\n",
    "    new_X = X_copy.merge(encoded_features, how = 'left', left_on = cat_name, right_index = True\n",
    "                        ).drop(columns = X_copy.columns[X_copy.columns.str.contains('^' + cat_name)])\n",
    "    return new_X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Target Encoding On Soil Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PProb_CovType1|Soil_Type</th>\n",
       "      <th>PProb_CovType2|Soil_Type</th>\n",
       "      <th>PProb_CovType3|Soil_Type</th>\n",
       "      <th>PProb_CovType4|Soil_Type</th>\n",
       "      <th>PProb_CovType5|Soil_Type</th>\n",
       "      <th>PProb_CovType6|Soil_Type</th>\n",
       "      <th>PProb_CovType7|Soil_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690814</td>\n",
       "      <td>0.059318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249869</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.112611</td>\n",
       "      <td>0.660270</td>\n",
       "      <td>0.014973</td>\n",
       "      <td>0.034795</td>\n",
       "      <td>0.177351</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.248967</td>\n",
       "      <td>0.493482</td>\n",
       "      <td>0.213355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044197</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01448</td>\n",
       "      <td>0.264039</td>\n",
       "      <td>0.605137</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.047973</td>\n",
       "      <td>0.049232</td>\n",
       "      <td>0.006296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611969</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354247</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PProb_CovType1|Soil_Type  PProb_CovType2|Soil_Type  \\\n",
       "0                   0.00000                  0.000000   \n",
       "1                   0.00000                  0.112611   \n",
       "2                   0.00000                  0.248967   \n",
       "3                   0.01448                  0.264039   \n",
       "4                   0.00000                  0.000000   \n",
       "\n",
       "   PProb_CovType3|Soil_Type  PProb_CovType4|Soil_Type  \\\n",
       "0                  0.690814                  0.059318   \n",
       "1                  0.660270                  0.014973   \n",
       "2                  0.493482                  0.213355   \n",
       "3                  0.605137                  0.012843   \n",
       "4                  0.611969                  0.033784   \n",
       "\n",
       "   PProb_CovType5|Soil_Type  PProb_CovType6|Soil_Type  \\\n",
       "0                  0.000000                  0.249869   \n",
       "1                  0.034795                  0.177351   \n",
       "2                  0.000000                  0.044197   \n",
       "3                  0.047973                  0.049232   \n",
       "4                  0.000000                  0.354247   \n",
       "\n",
       "   PProb_CovType7|Soil_Type  \n",
       "0                  0.000000  \n",
       "1                  0.000000  \n",
       "2                  0.000000  \n",
       "3                  0.006296  \n",
       "4                  0.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each cell represents the posterior probability of a cover type given the soil type,eg:encoded_SoilType.iloc[0,1] is \n",
    "#the posterior probability of a sample belonging to Cover type 1 given it belonging to soil type \n",
    "encoded_SoilType = target_encoding(X_train, y_train, 'Soil_Type')\n",
    "encoded_SoilType.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the target encoded soil type feature to the feature matrix\n",
    "#for validation set and test set, we transfer the categorical features using the benchmarks from the tranning set,\n",
    "#in order to avoid data leakage\n",
    "X_train_target = merge_encoded_features(X_train, encoded_SoilType, 'Soil_Type')\n",
    "X_val_target = merge_encoded_features(X_val, encoded_SoilType, 'Soil_Type')\n",
    "X_test_target = merge_encoded_features(X_test, encoded_SoilType, 'Soil_Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Target Encoding On Wilderness Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PProb_CovType1|Wilderness_Area</th>\n",
       "      <th>PProb_CovType2|Wilderness_Area</th>\n",
       "      <th>PProb_CovType3|Wilderness_Area</th>\n",
       "      <th>PProb_CovType4|Wilderness_Area</th>\n",
       "      <th>PProb_CovType5|Wilderness_Area</th>\n",
       "      <th>PProb_CovType6|Wilderness_Area</th>\n",
       "      <th>PProb_CovType7|Wilderness_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.405578</td>\n",
       "      <td>0.560433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.620827</td>\n",
       "      <td>0.301871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.345674</td>\n",
       "      <td>0.494063</td>\n",
       "      <td>0.056129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.029854</td>\n",
       "      <td>0.051799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080725</td>\n",
       "      <td>0.580725</td>\n",
       "      <td>0.074188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264361</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PProb_CovType1|Wilderness_Area  PProb_CovType2|Wilderness_Area  \\\n",
       "0                        0.405578                        0.560433   \n",
       "1                        0.620827                        0.301871   \n",
       "2                        0.345674                        0.494063   \n",
       "3                        0.000000                        0.080725   \n",
       "\n",
       "   PProb_CovType3|Wilderness_Area  PProb_CovType4|Wilderness_Area  \\\n",
       "0                        0.000000                        0.000000   \n",
       "1                        0.000000                        0.000000   \n",
       "2                        0.056129                        0.000000   \n",
       "3                        0.580725                        0.074188   \n",
       "\n",
       "   PProb_CovType5|Wilderness_Area  PProb_CovType6|Wilderness_Area  \\\n",
       "0                        0.014547                        0.000000   \n",
       "1                        0.000000                        0.000000   \n",
       "2                        0.022481                        0.029854   \n",
       "3                        0.000000                        0.264361   \n",
       "\n",
       "   PProb_CovType7|Wilderness_Area  \n",
       "0                        0.019442  \n",
       "1                        0.077302  \n",
       "2                        0.051799  \n",
       "3                        0.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each cell represents the posterior probability of a cover type given the wilderness area,\n",
    "#eg:encoded_WildernessArea.iloc[0,1] is the posterior probability of a sample belonging to Cover type 1 given it is\n",
    "#in wilderness area 0.\n",
    "encoded_WildernessArea = target_encoding(X_train, y_train, 'Wilderness_Area')\n",
    "encoded_WildernessArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the target encoded wilderness area feature to the feature matrix\n",
    "X_train_target = merge_encoded_features(X_train_target, encoded_WildernessArea, 'Wilderness_Area')\n",
    "X_val_target = merge_encoded_features(X_val_target, encoded_WildernessArea, 'Wilderness_Area')\n",
    "X_test_target = merge_encoded_features(X_test_target, encoded_WildernessArea, 'Wilderness_Area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'interact_Hillshade_9am3pm',\n",
       "       'interact_Hillshade_9amNoon', 'interact_Hillshade_3pmNoon',\n",
       "       'Euclidean_Distance_To_Hydrology', 'PProb_CovType1|Soil_Type',\n",
       "       'PProb_CovType2|Soil_Type', 'PProb_CovType3|Soil_Type',\n",
       "       'PProb_CovType4|Soil_Type', 'PProb_CovType5|Soil_Type',\n",
       "       'PProb_CovType6|Soil_Type', 'PProb_CovType7|Soil_Type',\n",
       "       'PProb_CovType1|Wilderness_Area', 'PProb_CovType2|Wilderness_Area',\n",
       "       'PProb_CovType3|Wilderness_Area', 'PProb_CovType4|Wilderness_Area',\n",
       "       'PProb_CovType5|Wilderness_Area', 'PProb_CovType6|Wilderness_Area',\n",
       "       'PProb_CovType7|Wilderness_Area'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_target.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Scale The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Scale Data With One Hot Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract categorical indice because we dont want to scale one hot encoded features\n",
    "cat_index = X.columns.str.contains('Wilderness_Area|Soil_Type', regex=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the training set\n",
    "cat_features = X_train.loc[:, cat_index]\n",
    "noncat_features = X_train.loc[:, ~cat_index]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(noncat_features)\n",
    "scaled_noncat_features = scaler.transform(noncat_features)\n",
    "#concatenate the scaled numeric features and categorical features\n",
    "X_train_onehot = pd.concat([pd.DataFrame(scaled_noncat_features,\n",
    "                                         columns = X.columns[~cat_index],\n",
    "                                         index = cat_features.index\n",
    "                                        ),cat_features], axis = 1)\n",
    "\n",
    "\n",
    "#standardize validation set\n",
    "cat_features = X_val.loc[:, cat_index]\n",
    "noncat_features = X_val.loc[:, ~cat_index]\n",
    "scaled_noncat_features = scaler.transform(noncat_features)\n",
    "#concatenate the scaled numeric features and categorical features\n",
    "X_val_onehot = pd.concat([pd.DataFrame(scaled_noncat_features,\n",
    "                                       columns = X.columns[~cat_index],\n",
    "                                       index = cat_features.index\n",
    "                                      ), cat_features], axis = 1)\n",
    "\n",
    "\n",
    "#standardize test set\n",
    "cat_features = X_test.loc[:, cat_index]\n",
    "noncat_features = X_test.loc[:, ~cat_index]\n",
    "scaled_noncat_features = scaler.transform(noncat_features)\n",
    "#concatenate the scaled numeric features and categorical features\n",
    "X_test_onehot = pd.concat([pd.DataFrame(scaled_noncat_features,\n",
    "                                        columns = X.columns[~cat_index],\n",
    "                                        index = cat_features.index\n",
    "                                       ), cat_features], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Scale Data With Target Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store column names for data storage in the future\n",
    "col_names_target = X_train_target.columns\n",
    "\n",
    "#standardize trianning set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_target)\n",
    "X_train_target = scaler.transform(X_train_target)\n",
    "\n",
    "#standardize validation set\n",
    "X_val_target = scaler.transform(X_val_target)\n",
    "\n",
    "#standardize validation set\n",
    "X_test_target = scaler.transform(X_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Perform Oversampling On the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to address the issue of class imblance, we perform oversampling on the trainning set, and\n",
    "keep validation set and test set intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling data with one hot encoded features\n",
    "sm1 = BorderlineSMOTE(random_state=42)\n",
    "X_train_onehot_res, y_train_onehot_res = sm1.fit_resample(X_train_onehot, y_train)\n",
    "\n",
    "#oversample data with target encoded features \n",
    "sm2 = BorderlineSMOTE(random_state=42)\n",
    "X_train_target_res, y_train_target_res = sm2.fit_resample(X_train_target, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Compare One Hot Encoding and Target Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.94      0.95     34225\n",
      "           2       0.94      0.96      0.95     44506\n",
      "           3       0.96      0.91      0.93      6012\n",
      "           4       0.87      0.87      0.87       439\n",
      "           5       0.87      0.83      0.85      1595\n",
      "           6       0.89      0.86      0.88      2875\n",
      "           7       0.96      0.96      0.96      3310\n",
      "\n",
      "    accuracy                           0.94     92962\n",
      "   macro avg       0.92      0.90      0.91     92962\n",
      "weighted avg       0.94      0.94      0.94     92962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using one hot encoded features to fit a random forest model\n",
    "clf1 = RandomForestClassifier(random_state=42, n_jobs = -1)\n",
    "clf1.fit(X_train_onehot_res, y_train_onehot_res.values.ravel())\n",
    "pred_y_val1 = clf1.predict(X_val_onehot)\n",
    "\n",
    "print(classification_report(pred_y_val1, y_val.values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.95      0.95     34178\n",
      "           2       0.95      0.97      0.96     44579\n",
      "           3       0.96      0.92      0.94      5988\n",
      "           4       0.87      0.88      0.88       437\n",
      "           5       0.88      0.83      0.85      1619\n",
      "           6       0.90      0.88      0.89      2840\n",
      "           7       0.97      0.96      0.96      3321\n",
      "\n",
      "    accuracy                           0.95     92962\n",
      "   macro avg       0.93      0.91      0.92     92962\n",
      "weighted avg       0.95      0.95      0.95     92962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using one target encoded features to fit a random forest model\n",
    "clf2 = RandomForestClassifier(random_state=42, n_jobs = -1)\n",
    "clf2.fit(X_train_target_res,  y_train_target_res.values.ravel())\n",
    "pred_y_val2 = clf2.predict(X_val_target)\n",
    "\n",
    "print(classification_report(pred_y_val2, y_val.values.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model fitting on target encoded features comprehensively outperforms the one fitting on encoded features. Most of the socres in precision, recall, f1-score have a 1% improvement, so we will keep the the feature matrix containing target encode features for our future modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save trainning set\n",
    "train_new = pd.DataFrame(X_train_target_res, columns = col_names_target).join(y_train_target_res)\n",
    "datapath = '../data'\n",
    "train_new.to_csv(datapath + '/training_step3.csv', index=False)\n",
    "\n",
    "#save validation set\n",
    "val_new = pd.DataFrame(X_val_target, columns = col_names_target, index = y_val.index).join(y_val)\n",
    "val_new.to_csv(datapath + '/validation_step3.csv', index=False)\n",
    "\n",
    "#save validation set\n",
    "test_new = pd.DataFrame(X_test_target, columns = col_names_target, index = y_test.index).join(y_test)\n",
    "test_new.to_csv(datapath + '/test_step3.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
