{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Load The  Forest Cover Type Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "      <th>interact_Hillshade_9am3pm</th>\n",
       "      <th>interact_Hillshade_9amNoon</th>\n",
       "      <th>interact_Hillshade_3pmNoon</th>\n",
       "      <th>Euclidean_Distance_To_Hydrology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>32708</td>\n",
       "      <td>51272</td>\n",
       "      <td>34336</td>\n",
       "      <td>258.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33220</td>\n",
       "      <td>51700</td>\n",
       "      <td>35485</td>\n",
       "      <td>212.084889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31590</td>\n",
       "      <td>55692</td>\n",
       "      <td>32130</td>\n",
       "      <td>275.769832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29036</td>\n",
       "      <td>56644</td>\n",
       "      <td>29036</td>\n",
       "      <td>269.235956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33000</td>\n",
       "      <td>51480</td>\n",
       "      <td>35100</td>\n",
       "      <td>153.003268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type36  Soil_Type37  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \\\n",
       "0            0            0            0           5   \n",
       "1            0            0            0           5   \n",
       "2            0            0            0           2   \n",
       "3            0            0            0           2   \n",
       "4            0            0            0           5   \n",
       "\n",
       "   interact_Hillshade_9am3pm  interact_Hillshade_9amNoon  \\\n",
       "0                      32708                       51272   \n",
       "1                      33220                       51700   \n",
       "2                      31590                       55692   \n",
       "3                      29036                       56644   \n",
       "4                      33000                       51480   \n",
       "\n",
       "   interact_Hillshade_3pmNoon  Euclidean_Distance_To_Hydrology  \n",
       "0                       34336                       258.000000  \n",
       "1                       35485                       212.084889  \n",
       "2                       32130                       275.769832  \n",
       "3                       29036                       269.235956  \n",
       "4                       35100                       153.003268  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covtype = pd.read_csv('../data/covtype_step2_features.csv')\n",
    "covtype.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = covtype.loc[:, covtype.columns != 'Cover_Type']\n",
    "y = covtype.loc[:, covtype.columns == 'Cover_Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into trainning set, validation set, and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state = 42, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state  = 42, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92962, 58)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Target Encoding On Categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set has categorical features that are one-hot encoded,where soil type consists of 40 types and wilderness area consists of 4 types. The higher dimension of the feature matrix sometimes may cause the algorithm having a hard time to learn form the data, so we also want to explore if target encoding the categorical features will results in a better outcome.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_label(X, cat_name):   \n",
    "    '''transform the one hot encoding columns to a label column'''\n",
    "    \n",
    "    X = X.iloc[:, X.columns.str.contains(pat = cat_name + '.*')] \n",
    "    Label = X.apply(lambda row : row.argmax(), axis = 1)\n",
    "    return Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding(X, target, cat_name):\n",
    "    '''return the posterior probility of a cover type given a sample belonging to a certain category'''\n",
    "    \n",
    "    label = onehot_to_label(X, cat_name)\n",
    "    label_target = pd.DataFrame({cat_name: label, 'target': target.Cover_Type})\n",
    "    posterior_prob = pd.DataFrame(index = range(label.nunique()))\n",
    "    \n",
    "    #total 7 cover types\n",
    "    n = 7\n",
    "    for i in range(1, n+1):\n",
    "        label_target['ith_Covtype'] = np.array(target == i).astype('int')\n",
    "        encoded_feature = 'PProb_CovType' + str(i) + '|' + cat_name\n",
    "        posterior_prob[encoded_feature] = label_target[['ith_Covtype', cat_name]\n",
    "                                                      ].groupby(cat_name).mean() \n",
    "\n",
    "        label_target.drop(columns  = 'ith_Covtype', inplace = True)  \n",
    "        \n",
    "    return posterior_prob\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_encoded_features(X, encoded_features, cat_name):\n",
    "    '''replace the one-hot encoded features by target encoded features'''\n",
    "    X_copy = X.copy()\n",
    "    X_copy[cat_name] = onehot_to_label(X_copy, cat_name)\n",
    "    new_X = X_copy.merge(encoded_features, how = 'left', left_on = cat_name, right_index = True\n",
    "                        ).drop(columns = X_copy.columns[X_copy.columns.str.contains('^' + cat_name)])\n",
    "    return new_X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Target Encoding On Soil Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PProb_CovType1|Soil_Type</th>\n",
       "      <th>PProb_CovType2|Soil_Type</th>\n",
       "      <th>PProb_CovType3|Soil_Type</th>\n",
       "      <th>PProb_CovType4|Soil_Type</th>\n",
       "      <th>PProb_CovType5|Soil_Type</th>\n",
       "      <th>PProb_CovType6|Soil_Type</th>\n",
       "      <th>PProb_CovType7|Soil_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690814</td>\n",
       "      <td>0.059318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249869</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.112611</td>\n",
       "      <td>0.660270</td>\n",
       "      <td>0.014973</td>\n",
       "      <td>0.034795</td>\n",
       "      <td>0.177351</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.248967</td>\n",
       "      <td>0.493482</td>\n",
       "      <td>0.213355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044197</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01448</td>\n",
       "      <td>0.264039</td>\n",
       "      <td>0.605137</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.047973</td>\n",
       "      <td>0.049232</td>\n",
       "      <td>0.006296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611969</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354247</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PProb_CovType1|Soil_Type  PProb_CovType2|Soil_Type  \\\n",
       "0                   0.00000                  0.000000   \n",
       "1                   0.00000                  0.112611   \n",
       "2                   0.00000                  0.248967   \n",
       "3                   0.01448                  0.264039   \n",
       "4                   0.00000                  0.000000   \n",
       "\n",
       "   PProb_CovType3|Soil_Type  PProb_CovType4|Soil_Type  \\\n",
       "0                  0.690814                  0.059318   \n",
       "1                  0.660270                  0.014973   \n",
       "2                  0.493482                  0.213355   \n",
       "3                  0.605137                  0.012843   \n",
       "4                  0.611969                  0.033784   \n",
       "\n",
       "   PProb_CovType5|Soil_Type  PProb_CovType6|Soil_Type  \\\n",
       "0                  0.000000                  0.249869   \n",
       "1                  0.034795                  0.177351   \n",
       "2                  0.000000                  0.044197   \n",
       "3                  0.047973                  0.049232   \n",
       "4                  0.000000                  0.354247   \n",
       "\n",
       "   PProb_CovType7|Soil_Type  \n",
       "0                  0.000000  \n",
       "1                  0.000000  \n",
       "2                  0.000000  \n",
       "3                  0.006296  \n",
       "4                  0.000000  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each cell represents the posterior probability of a cover type given the soil type,eg:encoded_SoilType.iloc[0,1] is \n",
    "#the posterior probability of a sample belonging to Cover type 1 given it belonging to soil type \n",
    "encoded_SoilType = target_encoding(X_train, y_train, 'Soil_Type')\n",
    "encoded_SoilType.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the target encoded soil type feature to the feature matrix\n",
    "#for validation set and test set, we transfer the categorical features using the benchmarks from the tranning set,\n",
    "#in order to avoid data leakage\n",
    "X_train_target = merge_encoded_features(X_train, encoded_SoilType, 'Soil_Type')\n",
    "X_val_target = merge_encoded_features(X_val, encoded_SoilType, 'Soil_Type')\n",
    "X_test_target = merge_encoded_features(X_test, encoded_SoilType, 'Soil_Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Target Encoding On Wilderness Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PProb_CovType1|Wilderness_Area</th>\n",
       "      <th>PProb_CovType2|Wilderness_Area</th>\n",
       "      <th>PProb_CovType3|Wilderness_Area</th>\n",
       "      <th>PProb_CovType4|Wilderness_Area</th>\n",
       "      <th>PProb_CovType5|Wilderness_Area</th>\n",
       "      <th>PProb_CovType6|Wilderness_Area</th>\n",
       "      <th>PProb_CovType7|Wilderness_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.405578</td>\n",
       "      <td>0.560433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.620827</td>\n",
       "      <td>0.301871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.345674</td>\n",
       "      <td>0.494063</td>\n",
       "      <td>0.056129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.029854</td>\n",
       "      <td>0.051799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080725</td>\n",
       "      <td>0.580725</td>\n",
       "      <td>0.074188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264361</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PProb_CovType1|Wilderness_Area  PProb_CovType2|Wilderness_Area  \\\n",
       "0                        0.405578                        0.560433   \n",
       "1                        0.620827                        0.301871   \n",
       "2                        0.345674                        0.494063   \n",
       "3                        0.000000                        0.080725   \n",
       "\n",
       "   PProb_CovType3|Wilderness_Area  PProb_CovType4|Wilderness_Area  \\\n",
       "0                        0.000000                        0.000000   \n",
       "1                        0.000000                        0.000000   \n",
       "2                        0.056129                        0.000000   \n",
       "3                        0.580725                        0.074188   \n",
       "\n",
       "   PProb_CovType5|Wilderness_Area  PProb_CovType6|Wilderness_Area  \\\n",
       "0                        0.014547                        0.000000   \n",
       "1                        0.000000                        0.000000   \n",
       "2                        0.022481                        0.029854   \n",
       "3                        0.000000                        0.264361   \n",
       "\n",
       "   PProb_CovType7|Wilderness_Area  \n",
       "0                        0.019442  \n",
       "1                        0.077302  \n",
       "2                        0.051799  \n",
       "3                        0.000000  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each cell represents the posterior probability of a cover type given the wilderness area,\n",
    "#eg:encoded_WildernessArea.iloc[0,1] is the posterior probability of a sample belonging to Cover type 1 given it is\n",
    "#in wilderness area 0.\n",
    "encoded_WildernessArea = target_encoding(X_train, y_train, 'Wilderness_Area')\n",
    "encoded_WildernessArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the target encoded wilderness area feature to the feature matrix\n",
    "X_train_target = merge_encoded_features(X_train_target, encoded_WildernessArea, 'Wilderness_Area')\n",
    "X_val_target = merge_encoded_features(X_val_target, encoded_WildernessArea, 'Wilderness_Area')\n",
    "X_test_target = merge_encoded_features(X_test_target, encoded_WildernessArea, 'Wilderness_Area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'interact_Hillshade_9am3pm',\n",
       "       'interact_Hillshade_9amNoon', 'interact_Hillshade_3pmNoon',\n",
       "       'Euclidean_Distance_To_Hydrology', 'PProb_CovType1|Soil_Type',\n",
       "       'PProb_CovType2|Soil_Type', 'PProb_CovType3|Soil_Type',\n",
       "       'PProb_CovType4|Soil_Type', 'PProb_CovType5|Soil_Type',\n",
       "       'PProb_CovType6|Soil_Type', 'PProb_CovType7|Soil_Type',\n",
       "       'PProb_CovType1|Wilderness_Area', 'PProb_CovType2|Wilderness_Area',\n",
       "       'PProb_CovType3|Wilderness_Area', 'PProb_CovType4|Wilderness_Area',\n",
       "       'PProb_CovType5|Wilderness_Area', 'PProb_CovType6|Wilderness_Area',\n",
       "       'PProb_CovType7|Wilderness_Area'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_target.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Scale The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Scale Data With One Hot Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract categorical indice because we dont want to scale one hot encoded features\n",
    "cat_index = X.columns.str.contains('Wilderness_Area|Soil_Type', regex=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the training set\n",
    "cat_features = X_train.loc[:, cat_index]\n",
    "noncat_features = X_train.loc[:, ~cat_index]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(noncat_features)\n",
    "scaled_noncat_features = scaler.transform(noncat_features)\n",
    "#concatenate the scaled numeric features and categorical features\n",
    "X_train_onehot = pd.concat([pd.DataFrame(scaled_noncat_features,\n",
    "                                         columns = X.columns[~cat_index],\n",
    "                                         index = cat_features.index\n",
    "                                        ),cat_features], axis = 1)\n",
    "\n",
    "\n",
    "#standardize validation set\n",
    "cat_features = X_val.loc[:, cat_index]\n",
    "noncat_features = X_val.loc[:, ~cat_index]\n",
    "scaled_noncat_features = scaler.transform(noncat_features)\n",
    "#concatenate the scaled numeric features and categorical features\n",
    "X_val_onehot = pd.concat([pd.DataFrame(scaled_noncat_features,\n",
    "                                       columns = X.columns[~cat_index],\n",
    "                                       index = cat_features.index\n",
    "                                      ), cat_features], axis = 1)\n",
    "\n",
    "\n",
    "#standardize test set\n",
    "cat_features = X_test.loc[:, cat_index]\n",
    "noncat_features = X_test.loc[:, ~cat_index]\n",
    "scaled_noncat_features = scaler.transform(noncat_features)\n",
    "#concatenate the scaled numeric features and categorical features\n",
    "X_test_onehot = pd.concat([pd.DataFrame(scaled_noncat_features,\n",
    "                                        columns = X.columns[~cat_index],\n",
    "                                        index = cat_features.index\n",
    "                                       ), cat_features], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Scale Data With Target Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store column names for data storage in the future\n",
    "col_names_target = X_train_target.columns\n",
    "\n",
    "#standardize trianning set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_target)\n",
    "X_train_target = scaler.transform(X_train_target)\n",
    "\n",
    "#standardize validation set\n",
    "X_val_target = scaler.transform(X_val_target)\n",
    "\n",
    "#standardize validation set\n",
    "X_test_target = scaler.transform(X_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use logistic regression to fit our baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The processing time for the baseline classifier is: 446.51308199999994 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "#fit the baseline model\n",
    "baseline = LogisticRegression(max_iter = 3000,random_state = 42).fit(X_train_onehot, y_train.values.ravel())\n",
    "pred_y_train = baseline.predict(X_train_onehot)\n",
    "\n",
    "end = time.process_time()\n",
    "print('The processing time for the baseline classifier is: ' + str(end-start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.71    135578\n",
      "           2       0.75      0.80      0.77    181312\n",
      "           3       0.69      0.79      0.74     22882\n",
      "           4       0.66      0.45      0.54      1759\n",
      "           5       0.48      0.03      0.06      6075\n",
      "           6       0.49      0.30      0.37     11115\n",
      "           7       0.74      0.58      0.65     13126\n",
      "\n",
      "    accuracy                           0.73    371847\n",
      "   macro avg       0.65      0.52      0.55    371847\n",
      "weighted avg       0.72      0.73      0.72    371847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train.values.ravel(),pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.70     33894\n",
      "           2       0.75      0.80      0.77     45328\n",
      "           3       0.70      0.80      0.75      5721\n",
      "           4       0.63      0.43      0.51       439\n",
      "           5       0.47      0.03      0.06      1519\n",
      "           6       0.49      0.31      0.38      2779\n",
      "           7       0.75      0.58      0.66      3282\n",
      "\n",
      "    accuracy                           0.73     92962\n",
      "   macro avg       0.64      0.52      0.55     92962\n",
      "weighted avg       0.72      0.73      0.72     92962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict the validation set\n",
    "pred_y_val = baseline.predict(X_val_onehot)\n",
    "print(classification_report(y_val.values.ravel(),pred_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report shows that the baseline model performs poorly in both of the trainning set and validation set. The scores on training set and validation have no big difference, indicating that the baseline model is underfitting and fails to captures some important information contributing to our target value.\n",
    "\n",
    "The macro average f1-scores on training set and validation set are only 0.55 and 0.54, which is mainly becasue the model is unable to sperate the minority classes from the majority one. We can see that only 4% of the samples belonging cover type 5 are successfully classfied. Less than 50% of the samples belonging to covertype 4 and 6 are successfully classfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Compare One Hot Encoding And Target Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above,one-hot encoding makes our data sparser at some levels and increases the computational cost. Now, holding the hyperparameters the same, let's explore if target encoding outperforms one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The processing time for the classifier clf1 is: 382.86451199999965 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "#fit data with target encoded features\n",
    "clf1 = LogisticRegression(max_iter = 3000,random_state = 42).fit(X_train_target,y_train.values.ravel())\n",
    "pred_y_train = clf1.predict(X_train_target)\n",
    "\n",
    "end = time.process_time()\n",
    "print('The processing time for the classifier clf1 is: ' + str(end-start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.70    135578\n",
      "           2       0.75      0.80      0.77    181312\n",
      "           3       0.69      0.79      0.74     22882\n",
      "           4       0.65      0.46      0.54      1759\n",
      "           5       0.48      0.04      0.07      6075\n",
      "           6       0.48      0.29      0.36     11115\n",
      "           7       0.73      0.56      0.63     13126\n",
      "\n",
      "    accuracy                           0.72    371847\n",
      "   macro avg       0.64      0.52      0.54    371847\n",
      "weighted avg       0.72      0.72      0.72    371847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train.values.ravel(),pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.69      0.70     33894\n",
      "           2       0.75      0.80      0.77     45328\n",
      "           3       0.69      0.80      0.74      5721\n",
      "           4       0.60      0.43      0.50       439\n",
      "           5       0.48      0.04      0.07      1519\n",
      "           6       0.48      0.28      0.36      2779\n",
      "           7       0.73      0.57      0.64      3282\n",
      "\n",
      "    accuracy                           0.72     92962\n",
      "   macro avg       0.63      0.52      0.54     92962\n",
      "weighted avg       0.72      0.72      0.71     92962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit the baseline model\n",
    "pred_y_val = clf1.predict(X_val_target)\n",
    "print(classification_report(y_val.values.ravel(),pred_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing time for this model is slightly less than the baseline, which meets our expectation since target encoding has reduced the total number of features from 58 to 28, more than a half! \n",
    "\n",
    "The classificaiton reports shows that the socres between two models are quite close. In order words, 28 features are likely to include majority of the information in 50 features. Thus, we will choose 28 features in our fulture modeling, considering less computational cost and mermory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save trainning set\n",
    "train_new = pd.DataFrame(X_train_target, columns = col_names_target,index = y_train.index).join(y_train)\n",
    "datapath = '../data'\n",
    "train_new.to_csv(datapath + '/training_step3.csv', index = False)\n",
    "\n",
    "#save validation set\n",
    "val_new = pd.DataFrame(X_val_target, columns = col_names_target, index = y_val.index).join(y_val)\n",
    "val_new.to_csv(datapath + '/validation_step3.csv', index = False)\n",
    "\n",
    "#save validation set\n",
    "test_new = pd.DataFrame(X_test_target, columns = col_names_target, index = y_test.index).join(y_test)\n",
    "test_new.to_csv(datapath + '/test_step3.csv', index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
